#!/usr/bin/env python3.12

import gradio as gr
import jinja2
import textwrap
import subprocess
import os


MODELS = [
    ("qwen3 0.6b", "ollama/qwen3:0.6b"),
    ("qwen3 4b", "ollama/qwen3:4b"),
    ("qwen3 8b", "ollama/qwen3:8b"),
    ("qwen3 14b", "ollama/qwen3:14b"),
    ("DeepSeek-R1", "deepseek/deepseek-reasoner"),
]

PROMPT_TEMPLATE = textwrap.dedent(
    """
    {{user_prompt}}
    {%- if selection and include_selection %}

    Selected code:
    ```
    {{selection}}
    ```

    {%- endif %}
    {%- if include_open_file %}

    ``` {{open_file}}
    {{open_file|cat}}
    ```

    {%- endif %}
    {%- for file in project_files %}

    ``` {{file}}
    {{file|cat}}
    ```
    {%- endfor %}
    {%- if dont_think %}

    /no_think
    {%- endif %}
    """
).strip("\n ")


def nvim(expr):
    out = subprocess.run(
        ["nvr", "--remote-expr", expr],
        capture_output=True,
        text=True,
    ).stdout
    return out

def copy(data):
    subprocess.run("pbcopy", text=True, input=data)

def vim_get_current_buffer():
    cur = nvim('bufname("")')
    return cur.replace(os.path.expanduser("~"), "~")


def vim_get_cursor():
    a = nvim('getpos(".")').split(", ")[1]
    b = nvim('getpos("v")').split(", ")[1]

    start = min(a, b)
    stop = max(a, b)
    if start == stop:
        return f"line {start}"
    return f"lines {start} - {stop}"


def get_project_files(project_dir):
    return (
        subprocess.check_output(
            ["git", "ls-files"],
            cwd=project_dir,
        )
        .decode()
        .splitlines()
    )


def get_git_projects_choices():
    gits = subprocess.run(
        [
            "find",
            os.path.expanduser("~"),
            "-maxdepth",
            "2",
            "-type",
            "d",
            "-name",
            ".git",
        ],
        check=False,
        capture_output=True,
        text=True,
    ).stdout.splitlines()
    choices = []
    for git in gits:
        project_dir = os.path.dirname(git)
        project_name = os.path.basename(project_dir)
        choices.append((project_name, project_dir))
    return choices


def cat(file):
    with open(file) as f:
        return f.read()


def chat_respond(message, chat_history, model):
    from litellm import completion

    response = completion(
        model=model,
        # temperature=temperature,
        # top_p=top_p,
        messages=chat_history + [{"role": "user", "content": message + "\n/no_think"}],
        stream=True,
    )

    resp = ""
    for part in response:
        content = part.choices[0].delta["content"] or ""
        resp += content
        yield resp


def submit(
    model,
    temperature,
    top_p,
    include_selection,
    include_open_file,
    dont_think,
    project_files,
    user_prompt,
    chat_history,
    project_dir,
    _,
    *,
    copy_button=False
):

    chat_history = []
    # chat_history.append(gr.ChatMessage(role="user", content="asdf"))
    chat_history.append(dict(role="assistant", content=""))

    env = jinja2.Environment()
    env.filters["cat"] = lambda f: cat(os.path.join(project_dir, os.path.expanduser(f)))
    template = env.from_string(PROMPT_TEMPLATE)
    prompt = template.render(open_file=vim_get_current_buffer(), **locals())

    if copy_button:
        copy(prompt)
        return

    from litellm import completion

    response = completion(
        model=model,
        temperature=temperature,
        top_p=top_p,
        messages=[
            {
                "content": prompt,
                "role": "user",
            },
        ],
        stream=True,
    )

    for part in response:
        chat_history[-1]["content"] += part.choices[0].delta["content"] or ""
        yield chat_history


with gr.Blocks() as demo:
    gr.Markdown("# Code Genie 2000")

    model = gr.Radio(
        MODELS,
        value="ollama/qwen3:4b",
        show_label=False,
    )

    with gr.Group(), gr.Accordion("Prompt generator"):

        with gr.Row():
            include_open_file = gr.Checkbox()
            gr.Timer(1).tick(
                lambda: gr.Checkbox(label=f"Include `{vim_get_current_buffer()}`"),
                outputs=include_open_file,
            )
            include_selection = gr.Checkbox(label="Include selection")
            gr.Timer(1).tick(
                lambda: gr.Checkbox(label=f"Include {vim_get_cursor()}"),
                outputs=include_selection,
            )
            dont_think = gr.Checkbox(label="Don't think (for qwen)", value=True)

        with gr.Row():
            project_dropdown = gr.Dropdown(
                ["<select project>"] + get_git_projects_choices(),
                label="Project",
                interactive=True,
            )

            project_files_dropdown = gr.Dropdown(
                ["<select project first>"],
                value=[],
                multiselect=True,
                label="Project files",
                scale=4,
            )

        project_dropdown.change(
            fn=lambda project: gr.Dropdown(choices=get_project_files(project)),
            inputs=project_dropdown,
            outputs=project_files_dropdown,
        )

        user_prompt = gr.TextArea(label="Header text")

        with gr.Accordion("More settings...", open=False):
            temperature = gr.Slider(
                0, 4, value=0.8, label="Temperature", info="How creative it is"
            )
            top_p = gr.Slider(
                0,
                0.9,
                value=0.8,
                label="Top p",
                info="Higher value for more diverse text.",
            )

        with gr.Row():
            submit_button = gr.Button(value="Send to Chat", variant="primary")
            copy_button = gr.Button(value="Copy to clipboard")

    chatbot = gr.Chatbot(
        allow_tags=True,
        height="calc(100vh - 80px)",
    )
    chat = gr.ChatInterface(
        fn=chat_respond,
        type="messages",
        additional_inputs=[model],
        chatbot=chatbot,
    )

    inputs = [
        model,
        temperature,
        top_p,
        include_selection,
        include_open_file,
        dont_think,
        project_files_dropdown,
        user_prompt,
        chatbot,
        project_dropdown,
        submit_button,
    ]

    submit_button.click(submit, inputs=inputs, outputs=[chatbot])
    copy_button.click(lambda *args: submit(*args, copy_button=True), inputs=inputs, outputs=[chatbot])
    user_prompt.submit(submit, inputs=inputs, outputs=[chatbot])

demo.launch()
